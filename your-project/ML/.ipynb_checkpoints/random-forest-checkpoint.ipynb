{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('../framinghan_function/framingham-score-risk.csv')\n",
    "df   = pd.DataFrame(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>fram_score</th>\n",
       "      <th>risk</th>\n",
       "      <th>risk_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>53.0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>52.0</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  gender   BMI  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  \\\n",
       "0      50.0       2  22.0    110     80            1     1      0     0   \n",
       "1      55.0       1  35.0    140     90            3     1      0     0   \n",
       "2      52.0       1  24.0    130     70            3     1      0     0   \n",
       "3      48.0       2  29.0    150    100            1     1      0     0   \n",
       "4      48.0       1  23.0    100     60            1     1      0     0   \n",
       "...     ...     ...   ...    ...    ...          ...   ...    ...   ...   \n",
       "69995  53.0       2  27.0    120     80            1     1      1     0   \n",
       "69996  62.0       1  50.0    140     90            2     2      0     0   \n",
       "69997  52.0       2  31.0    180     90            3     1      0     1   \n",
       "69998  61.0       1  27.0    135     80            1     2      0     0   \n",
       "69999  56.0       1  25.0    120     80            2     1      0     0   \n",
       "\n",
       "       active  cardio  fram_score  risk  risk_group  \n",
       "0           1       0           3  0.05           2  \n",
       "1           1       1          12  0.13           4  \n",
       "2           0       1           9  0.08           3  \n",
       "3           1       1           5  0.08           3  \n",
       "4           0       0           0  0.02           1  \n",
       "...       ...     ...         ...   ...         ...  \n",
       "69995       1       0           5  0.08           3  \n",
       "69996       1       1          15  0.20           5  \n",
       "69997       0       1           9  0.20           5  \n",
       "69998       0       1          12  0.13           4  \n",
       "69999       1       0           8  0.07           3  \n",
       "\n",
       "[70000 rows x 14 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['ap_hi', 'ap_lo', 'cholesterol', 'cardio', 'fram_score', 'risk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>risk_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>53.0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>52.0</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  gender   BMI  gluc  smoke  alco  active  risk_group\n",
       "0      50.0       2  22.0     1      0     0       1           2\n",
       "1      55.0       1  35.0     1      0     0       1           4\n",
       "2      52.0       1  24.0     1      0     0       0           3\n",
       "3      48.0       2  29.0     1      0     0       1           3\n",
       "4      48.0       1  23.0     1      0     0       0           1\n",
       "...     ...     ...   ...   ...    ...   ...     ...         ...\n",
       "69995  53.0       2  27.0     1      1     0       1           3\n",
       "69996  62.0       1  50.0     2      0     0       1           5\n",
       "69997  52.0       2  31.0     1      0     1       0           5\n",
       "69998  61.0       1  27.0     2      0     0       0           4\n",
       "69999  56.0       1  25.0     1      0     0       1           3\n",
       "\n",
       "[70000 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"risk_group\"], axis=1)\n",
    "y = df[\"risk_group\"]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=80, max_features=3, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=5,\n",
       "                      min_samples_split=12, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=200, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "\n",
    "#First iteration of the rf\n",
    "#rf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "\n",
    "rf = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=80, max_features=3, max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.0,\n",
    "                      min_impurity_split=None, min_samples_leaf=5,\n",
    "                      min_samples_split=12, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=200, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Results obtained after calculating 'grid_search.best_estimator_'\n",
    "# RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "#                       max_depth=80, max_features=3, max_leaf_nodes=None,\n",
    "#                       max_samples=None, min_impurity_decrease=0.0,\n",
    "#                       min_impurity_split=None, min_samples_leaf=5,\n",
    "#                       min_samples_split=12, min_weight_fraction_leaf=0.0,\n",
    "#                       n_estimators=200, n_jobs=None, oob_score=False,\n",
    "#                       random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.45 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "y_pred = np.around(rf.predict(X_test))\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred - y_test)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.99 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / y_test)# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's evaluate the best number of stimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.49 degrees.\n",
      "Accuracy: 80.54 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.49 degrees.\n",
      "Accuracy: 80.89 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.48 degrees.\n",
      "Accuracy: 81.1 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.48 degrees.\n",
      "Accuracy: 81.1 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.48 degrees.\n",
      "Accuracy: 81.2 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.48 degrees.\n",
      "Accuracy: 81.15 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.48 degrees.\n",
      "Accuracy: 81.14 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.48 degrees.\n",
      "Accuracy: 81.18 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.28 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.25 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.27 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.21 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.27 %.\n",
      "[1. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.31 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.29 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.37 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.36 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.34 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.38 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.37 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.33 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.34 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.35 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.34 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.4 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.39 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.39 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.31 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.34 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.33 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.32 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.37 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.37 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.37 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.4 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.4 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.35 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.4 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.41 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.38 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.37 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.4 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.4 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.37 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.42 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.4 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 3. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.46 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.45 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.47 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.47 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.45 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.45 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.45 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.46 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.47 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.47 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.47 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.46 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.41 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.42 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.45 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.45 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.46 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.45 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.46 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.45 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.45 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.45 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.39 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.43 %.\n",
      "[2. 3. 1. ... 4. 2. 4.]\n",
      "Mean Absolute Error: 0.47 degrees.\n",
      "Accuracy: 81.44 %.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with 1000 decision trees\n",
    "\n",
    "n_range = range(100)\n",
    "accuracy_list = []\n",
    "\n",
    "for n in n_range:\n",
    "    rf = RandomForestRegressor(n_estimators = n+1, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    y_pred = np.around(rf.predict(X_test))\n",
    "\n",
    "    print(y_pred)\n",
    "\n",
    "    # Calculate the absolute errors\n",
    "    errors = abs(y_pred - y_test)\n",
    "\n",
    "    # Print out the mean absolute error (mae)\n",
    "    print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "    # Calculate mean absolute percentage error (MAPE)\n",
    "    mape = 100 * (errors / y_test)# Calculate and display accuracy\n",
    "    accuracy = 100 - np.mean(mape)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'testing accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_range = list(range(100))\n",
    "\n",
    "plt.plot(n_range, accuracy_list)\n",
    "plt.xlabel(\"value of estimator's number\")\n",
    "plt.ylabel('testing accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}# Create a based model\n",
    "rf = RandomForestRegressor()# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 26.9min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed: 36.7min finished\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test \n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_params_\n",
    "\n",
    "best_grid = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=80, max_features=3, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=5,\n",
       "                      min_samples_split=12, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=200, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
